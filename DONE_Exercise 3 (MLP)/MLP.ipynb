{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications of MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWZyYmS_UE_L"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxkJoQBkUIHC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Analysis\n",
    "---\n",
    "- Churn refers to the number of customers who stop doing business with a company within a given time period. <br><br>\n",
    "- A high churn rate can be a sign of customer dissatisfaction or a problem with the company's products or services. It can also be caused by factors outside of the company's control, such as a competitor offering a better deal.<br><br>\n",
    "- Churning customers can have a number of economic disadvantages for a business, including:<br>\n",
    "    - Loss of revenue. When customers churn, they stop paying for the company's products or services. This can lead to a significant loss of revenue, especially for businesses that rely on recurring revenue.<br><br>\n",
    "    - Increased marketing costs. To replace lost customers, businesses often need to spend more on marketing and sales. This can be a significant expense, especially for businesses with a high churn rate.<br><br>\n",
    "    - Damage to brand reputation. When customers churn, they may spread negative word-of-mouth about the company. This can damage the company's brand reputation and make it more difficult to attract new customers.<br><br>\n",
    "    - Increased customer acquisition costs. It is more expensive to acquire new customers than to retain existing customers. This is because new customers are less likely to be familiar with the company's products or services and may require more hand-holding.<br><br>\n",
    "    - Decreased customer lifetime value. The customer lifetime value (CLV) is the total amount of money that a customer is expected to spend with a company over their lifetime. When customers churn, the company loses out on the potential future revenue that they could have generated from that customer.<br><br>\n",
    "\n",
    "- The economic disadvantages of churning customers can be significant, so it is important for businesses to take steps to reduce churn. Some common ways to reduce churn include:<br><br>\n",
    "\n",
    "    - Providing excellent customer service. This means being responsive to customer inquiries, resolving problems quickly and efficiently, and going the extra mile to make sure that customers are satisfied.<br><br>\n",
    "    - Offering competitive prices. This means keeping prices in line with the competition and offering discounts and promotions to encourage customers to stay with the company.<br><br>\n",
    "    - Constantly innovating. This means keeping up with the latest trends and offering new and improved products and services to keep customers engaged.<br><br>\n",
    "    - Personalizing the customer experience. This means getting to know each customer's individual needs and preferences and tailoring the company's offerings accordingly.\n",
    "<br><br>\n",
    "- By taking steps to reduce churn, businesses can improve their bottom line and ensure long-term success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1E0Q3aoKUCRX"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKWAkFVGUU0Z"
   },
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXUkhkMfU4wq"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('bank_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 3:-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CreditScore Geography  Gender Age Tenure    Balance NumOfProducts  \\\n",
       "0            619    France  Female  42      2        0.0             1   \n",
       "1            608     Spain  Female  41      1   83807.86             1   \n",
       "2            502    France  Female  42      8   159660.8             3   \n",
       "3            699    France  Female  39      1        0.0             2   \n",
       "4            850     Spain  Female  43      2  125510.82             1   \n",
       "...          ...       ...     ...  ..    ...        ...           ...   \n",
       "9995         771    France    Male  39      5        0.0             2   \n",
       "9996         516    France    Male  35     10   57369.61             1   \n",
       "9997         709    France  Female  36      7        0.0             1   \n",
       "9998         772   Germany    Male  42      3   75075.31             2   \n",
       "9999         792    France  Female  28      4  130142.79             1   \n",
       "\n",
       "     HasCrCard IsActiveMember EstimatedSalary  \n",
       "0            1              1       101348.88  \n",
       "1            0              1       112542.58  \n",
       "2            1              0       113931.57  \n",
       "3            0              0        93826.63  \n",
       "4            1              1         79084.1  \n",
       "...        ...            ...             ...  \n",
       "9995         1              0        96270.64  \n",
       "9996         1              1       101699.77  \n",
       "9997         0              1        42085.58  \n",
       "9998         1              0        92888.52  \n",
       "9999         1              0        38190.78  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X, columns = [\"CreditScore\",\"Geography\",\"Gender\",\"Age\",\"Tenure\",\"Balance\",\"NumOfProducts\",\"HasCrCard\",\"IsActiveMember\",\"EstimatedSalary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Exited\n",
       "0          1\n",
       "1          0\n",
       "2          1\n",
       "3          0\n",
       "4          0\n",
       "...      ...\n",
       "9995       0\n",
       "9996       0\n",
       "9997       1\n",
       "9998       1\n",
       "9999       0\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y, columns = [\"Exited\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "VYP9cQTWbzuI",
    "outputId": "797e7a64-9bac-436a-8c9c-94437e5e7587"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 'France', 'Female', ..., 1, 1, 101348.88],\n",
       "       [608, 'Spain', 'Female', ..., 0, 1, 112542.58],\n",
       "       [502, 'France', 'Female', ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [709, 'France', 'Female', ..., 0, 1, 42085.58],\n",
       "       [772, 'Germany', 'Male', ..., 1, 0, 92888.52],\n",
       "       [792, 'France', 'Female', ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "38vKGE6Nb2RR",
    "outputId": "a815e42a-e0dd-4cb5-ab97-b17ead98fbc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N6bQ0UgSU-NJ"
   },
   "source": [
    "### Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "le5MJreAbW52"
   },
   "source": [
    "Label Encoding the \"Gender\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PxVKWXxLbczC"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X[:, 2] = le.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "-M1KboxFb6OO",
    "outputId": "e2b8c7e8-0cbc-4cdf-f4eb-7f0853a00b88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 0 ... 1 1 101348.88]\n",
      " [608 'Spain' 0 ... 0 1 112542.58]\n",
      " [502 'France' 0 ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 0 ... 0 1 42085.58]\n",
      " [772 'Germany' 1 ... 1 0 92888.52]\n",
      " [792 'France' 0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CUxGZezpbMcb"
   },
   "source": [
    "One Hot Encoding the \"Geography\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AMXC8-KMVirw"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "ZcxwEon-b8nV",
    "outputId": "23a98af4-5e33-4b26-c27b-f06e3c5d2baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
      " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
      " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
      " ...\n",
      " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
      " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
      " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vHol938cW8zd"
   },
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-TDt0Y_XEfc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RE_FcHyfV3TQ"
   },
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ViCrE00rV8Sk"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-zfEzkRVXIwF"
   },
   "source": [
    "## Part 2 - Building the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KvdeScabXtlB"
   },
   "source": [
    "### Initializing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3dtrScHxXQox"
   },
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rP6urV6SX7kS"
   },
   "source": [
    "### Adding the input layer and the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bppGycBXYCQr"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BELWAc_8YJze"
   },
   "source": [
    "### Adding the second hidden layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JneR0u0sYRTd"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyNEe6RXYcU4"
   },
   "source": [
    "### Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cn3x41RBYfvY"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JT4u2S1_Y4WG"
   },
   "source": [
    "## Part 3 - Training the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GWlJChhY_ZI"
   },
   "source": [
    "### Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fG3RrwDXZEaS"
   },
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0QR_G5u7ZLSM"
   },
   "source": [
    "### Training the ANN on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nHZ-LKv_ZRb3",
    "outputId": "718cc4b0-b5aa-40f0-9b20-d3d31730a531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 660us/step - loss: 0.8642 - accuracy: 0.4692\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 632us/step - loss: 0.5532 - accuracy: 0.7846\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.7971\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 668us/step - loss: 0.4571 - accuracy: 0.8040\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 628us/step - loss: 0.4335 - accuracy: 0.8152\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 653us/step - loss: 0.4173 - accuracy: 0.8214\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 658us/step - loss: 0.3983 - accuracy: 0.8317\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 657us/step - loss: 0.3774 - accuracy: 0.8440\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 703us/step - loss: 0.3636 - accuracy: 0.8514\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 642us/step - loss: 0.3571 - accuracy: 0.8519\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 642us/step - loss: 0.3529 - accuracy: 0.8543\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 689us/step - loss: 0.3507 - accuracy: 0.8544\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 647us/step - loss: 0.3487 - accuracy: 0.8561\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 634us/step - loss: 0.3473 - accuracy: 0.8556\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 656us/step - loss: 0.3465 - accuracy: 0.8565\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 638us/step - loss: 0.3453 - accuracy: 0.8575\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 666us/step - loss: 0.3446 - accuracy: 0.8593\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 659us/step - loss: 0.3440 - accuracy: 0.8593\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 664us/step - loss: 0.3434 - accuracy: 0.8575\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 680us/step - loss: 0.3424 - accuracy: 0.8593\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 655us/step - loss: 0.3418 - accuracy: 0.8600\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 639us/step - loss: 0.3412 - accuracy: 0.8601\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 629us/step - loss: 0.3409 - accuracy: 0.8601\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 696us/step - loss: 0.3399 - accuracy: 0.8605\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 671us/step - loss: 0.3399 - accuracy: 0.8601\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 670us/step - loss: 0.3394 - accuracy: 0.8614\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 659us/step - loss: 0.3390 - accuracy: 0.8606\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 647us/step - loss: 0.3384 - accuracy: 0.8597\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 640us/step - loss: 0.3381 - accuracy: 0.8608\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 719us/step - loss: 0.3377 - accuracy: 0.8633\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 651us/step - loss: 0.3374 - accuracy: 0.8611\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 640us/step - loss: 0.3367 - accuracy: 0.8609\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 683us/step - loss: 0.3365 - accuracy: 0.8609\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 644us/step - loss: 0.3361 - accuracy: 0.8618\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 637us/step - loss: 0.3358 - accuracy: 0.8631\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 648us/step - loss: 0.3352 - accuracy: 0.8630\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 626us/step - loss: 0.3354 - accuracy: 0.8631\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.3348 - accuracy: 0.8621\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.3346 - accuracy: 0.8644\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 650us/step - loss: 0.3346 - accuracy: 0.8620\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 643us/step - loss: 0.3343 - accuracy: 0.8641\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 642us/step - loss: 0.3339 - accuracy: 0.8604\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 659us/step - loss: 0.3335 - accuracy: 0.8626\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 658us/step - loss: 0.3332 - accuracy: 0.8635\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 679us/step - loss: 0.3332 - accuracy: 0.8640\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.3330 - accuracy: 0.8625\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 669us/step - loss: 0.3329 - accuracy: 0.8634\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 656us/step - loss: 0.3327 - accuracy: 0.8625\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 694us/step - loss: 0.3323 - accuracy: 0.8649\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 706us/step - loss: 0.3321 - accuracy: 0.8627\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 673us/step - loss: 0.3320 - accuracy: 0.8634\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 701us/step - loss: 0.3319 - accuracy: 0.8644\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 645us/step - loss: 0.3319 - accuracy: 0.8634\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 666us/step - loss: 0.3318 - accuracy: 0.8631\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 669us/step - loss: 0.3313 - accuracy: 0.8627\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 652us/step - loss: 0.3312 - accuracy: 0.8633\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 639us/step - loss: 0.3315 - accuracy: 0.8626\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 672us/step - loss: 0.3314 - accuracy: 0.8637\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 631us/step - loss: 0.3313 - accuracy: 0.8629\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 683us/step - loss: 0.3314 - accuracy: 0.8621\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 639us/step - loss: 0.3310 - accuracy: 0.8633\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 707us/step - loss: 0.3312 - accuracy: 0.8629\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 647us/step - loss: 0.3313 - accuracy: 0.8635\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 692us/step - loss: 0.3307 - accuracy: 0.8640\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 643us/step - loss: 0.3309 - accuracy: 0.8640\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 702us/step - loss: 0.3308 - accuracy: 0.8633\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 665us/step - loss: 0.3307 - accuracy: 0.8644\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.3305 - accuracy: 0.8640\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 640us/step - loss: 0.3303 - accuracy: 0.8635\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 688us/step - loss: 0.3303 - accuracy: 0.8631\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 645us/step - loss: 0.3302 - accuracy: 0.8629\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 714us/step - loss: 0.3301 - accuracy: 0.8644\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 658us/step - loss: 0.3301 - accuracy: 0.8640\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 635us/step - loss: 0.3300 - accuracy: 0.8631\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 645us/step - loss: 0.3298 - accuracy: 0.8643\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 654us/step - loss: 0.3299 - accuracy: 0.8640\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 651us/step - loss: 0.3297 - accuracy: 0.8626\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.3298 - accuracy: 0.8631\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 660us/step - loss: 0.3298 - accuracy: 0.8636\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.3299 - accuracy: 0.8656\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 0s 675us/step - loss: 0.3298 - accuracy: 0.8630\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 698us/step - loss: 0.3293 - accuracy: 0.8650\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 651us/step - loss: 0.3297 - accuracy: 0.8630\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 723us/step - loss: 0.3293 - accuracy: 0.8650\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 656us/step - loss: 0.3296 - accuracy: 0.8639\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 685us/step - loss: 0.3297 - accuracy: 0.8636\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 643us/step - loss: 0.3292 - accuracy: 0.8636\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.3292 - accuracy: 0.8641\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 645us/step - loss: 0.3292 - accuracy: 0.8634\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 645us/step - loss: 0.3290 - accuracy: 0.8641\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 728us/step - loss: 0.3286 - accuracy: 0.8654\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 648us/step - loss: 0.3295 - accuracy: 0.8639\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.3292 - accuracy: 0.8631\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 665us/step - loss: 0.3291 - accuracy: 0.8636\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 655us/step - loss: 0.3290 - accuracy: 0.8633\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.3286 - accuracy: 0.8643\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 663us/step - loss: 0.3287 - accuracy: 0.8641\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 660us/step - loss: 0.3285 - accuracy: 0.8648\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 637us/step - loss: 0.3288 - accuracy: 0.8625\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 665us/step - loss: 0.3286 - accuracy: 0.8636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x183cefc2f50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJj5k2MxZga3"
   },
   "source": [
    "## Part 4 - Making the predictions and evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7yx47jPZt11"
   },
   "source": [
    "### Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "nIyEeQdRZwgs",
    "outputId": "82330ba8-9bdc-4fd1-d3cf-b6d78ee7c2a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 589us/step\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o0oyfLWoaEGw"
   },
   "source": [
    "### Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ci6K_r6LaF6P",
    "outputId": "4d854e9e-22d5-432f-f6e5-a102fe3ae0bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1514   81]\n",
      " [ 193  212]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.863"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 750x750 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Homework**\n",
    "- Use the dataset: https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset.\n",
    "- Experiment with the number of hidden layers, and the number of units in the hidden layer.\n",
    "- Try to experiment on the activation functions in the hidden layer https://www.tensorflow.org/api_docs/python/tf/keras/activations\n",
    "- Try to experiment with the optimizer: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
    "- Check the accuracy, specificity, and sensitivity of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "artificial_neural_network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
